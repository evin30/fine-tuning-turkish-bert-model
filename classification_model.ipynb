{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7S4C5ou6vAezy+FEjHXF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktoprakucar/fine-tuning-turkish-bert-model/blob/master/classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgcx4jPKRd8V",
        "colab_type": "text"
      },
      "source": [
        "koda geçmeden önce, koddaki BERT ile ilgili olan kısımları https://mccormickml.com/2019/07/22/BERT-fine-tuning/ linkindeki kodlardan yararlanarak oluşturduğumu belirtmek isterim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrYO6HDoRNNP",
        "colab_type": "code",
        "outputId": "10dded42-ef74-4f6e-bc0d-53fadc341a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCCSYp9sSlSD",
        "colab_type": "code",
        "outputId": "6e91d584-1973-4399-ce98-a543d04810e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dglYrRbCbR8Y",
        "colab_type": "text"
      },
      "source": [
        "dosyayı drive'dan okuyabilmeniz için google drive'daki ana klasörünüze resource isminde bir klasör oluşturup, kaggle'dan indirdiğimiz dosyayı *turkish_text_data*.csv olarak kaydetmemiz gerekiyor.\n",
        "\n",
        "kaggle data'sını linkten indirebilirsiniz: https://www.kaggle.com/savasy/ttc4900"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tc-DVN1S448",
        "colab_type": "code",
        "outputId": "383665a6-f720-4b22-ab1d-061af07af09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set environment as googledrive to folder \"resource\"\n",
        "data_path =  \"/resource/\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = \"/content/drive/My Drive/resource/\"\n",
        "\n",
        "except:\n",
        "    print(\"You are not working in Colab at the moment :(\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nt6KR1ZTMEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(data_path + 'turkish_text_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaWQQe3yTYab",
        "colab_type": "code",
        "outputId": "e25e3384-43da-4028-8a38-a0c2145a6053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4900 entries, 0 to 4899\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  4900 non-null   object\n",
            " 1   text      4900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 76.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOTi-A1UTc24",
        "colab_type": "code",
        "outputId": "17f47dd6-3ff2-4ac5-b9f6-b55e55da6236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>dunya</td>\n",
              "      <td>berdimuhamedov ermenistan ı ziyaret edecek tü...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3029</th>\n",
              "      <td>saglik</td>\n",
              "      <td>koah aids kadar tehlikeli söz konusu hastalık...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>spor</td>\n",
              "      <td>webo carvalhal den izin istedi geçen sezon is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>kultur</td>\n",
              "      <td>büyük ev abluka dan ilk albüm bugün kadar ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4785</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>facebook ta yeni dönem sosyal ağ devi faceboo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>dunya</td>\n",
              "      <td>maske takana 10 yıl hapis kanada da herhangi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>nasa nın iki uzay aracı emekli oldu nasa ya a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>dunya</td>\n",
              "      <td>kosova ya türkiye den destek dışişleri_bakanl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>spor</td>\n",
              "      <td>beşiktaş seri peşinde spor_toto_süper_lig in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4459</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>dünya dışındaki yaşamı dünyada arıyorlar bili...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "808       dunya    berdimuhamedov ermenistan ı ziyaret edecek tü...\n",
              "3029     saglik    koah aids kadar tehlikeli söz konusu hastalık...\n",
              "3545       spor    webo carvalhal den izin istedi geçen sezon is...\n",
              "2632     kultur    büyük ev abluka dan ilk albüm bugün kadar ver...\n",
              "4785  teknoloji    facebook ta yeni dönem sosyal ağ devi faceboo...\n",
              "1074      dunya    maske takana 10 yıl hapis kanada da herhangi ...\n",
              "4714  teknoloji    nasa nın iki uzay aracı emekli oldu nasa ya a...\n",
              "720       dunya    kosova ya türkiye den destek dışişleri_bakanl...\n",
              "3997       spor    beşiktaş seri peşinde spor_toto_süper_lig in ...\n",
              "4459  teknoloji    dünya dışındaki yaşamı dünyada arıyorlar bili..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEcaS2orThoy",
        "colab_type": "code",
        "outputId": "fe6af655-54d5-4853-dbef-35492b380006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df.groupby('category').size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category\n",
              "dunya         700\n",
              "ekonomi       700\n",
              "kultur        700\n",
              "saglik        700\n",
              "siyaset       700\n",
              "spor          700\n",
              "teknoloji     700\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BW4WCeTb1a5",
        "colab_type": "text"
      },
      "source": [
        "Kategorik olan label'ları modelde kullanabilmemiz için kategori kolonunu encode etmemiz gerekiyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOo9dA56_7Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['encoded_categories'] = LabelEncoder().fit_transform(df['category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMsdi2PzcAdY",
        "colab_type": "text"
      },
      "source": [
        "Bert için gerekli olan 2 ana objeyi, tokenizer'ı ve model'i hugging face'ten indirebilirsiniz: https://huggingface.co/models\n",
        "\n",
        "tokenizer'ı, önceden sahip olunan kelime haznesini kullanarak metinini ögelerini ayırma işleminde kullanılan araç olarak tanımlayabiliriz. bu tokenizer'daki kelimelere aşağıdaki linkten ulaşabilirsiniz: \n",
        "https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-128k-uncased/vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtmbRhroAtCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DzbC8f7AxAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.text.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPgQuTUGA1ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCqcXz6scVLD",
        "colab_type": "text"
      },
      "source": [
        "burada elimizdeki metin verisini %80 ve %20 oranıyla, sırasıyla training ve test olarak ikiye bölüyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsHlvfa1A9J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = df.groupby('category').apply(lambda x : x.sample(frac = 0.8))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYiFqjplA_e4",
        "colab_type": "code",
        "outputId": "76a42e43-4477-4436-d63b-58470e42020a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Training: \", len(training))\n",
        "print(\"Test: \", len(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:  3920\n",
            "Test:  838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PuTo9fHBBFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_texts = training.text.values\n",
        "training_labels = training.encoded_categories.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u793WoNkclVP",
        "colab_type": "text"
      },
      "source": [
        "bu kısımda metin verisini modelde kullanmak üzere işliyoruz. öncelikle cümledeki kelimeler indirdiğimiz tokenizer ile tokenize ediliyor, sonrasında sınıflandırma probleminin çözülebilmesi için gerekli olan token'lar cümlenin sonuna ve başına ekleniyor. cümle maksimum uzunluktan kısaysa, input vektörümüz sabit uzunlukta olduğu için boşluklar dolduruluyor, uzunsa metin limit kadar kelime ile ifade ediliyor. attention mask'leri oluşturuluyor ve metinler işlemin sonucunda tensor objesi olarak geri dönüyor.\n",
        "\n",
        "aşağıdaki çıktıda da görüldüğü üzere, metindeki kelimeler tokenizer'daki kelimelerin id'leri ile ifade ediliyor ve bu şekilde işleme sokuluyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AavMUW7oBESR",
        "colab_type": "code",
        "outputId": "e637534e-167d-4178-c157-8f49e45223db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in training_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(training_labels)\n",
        "\n",
        "print('Original: ', training_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:   ankara obama ya sıcak abd seçmeni bugün yalnız kendi kaderine değil dünyanın kaderine yön verecek ankara 4 yıldır birçok konuda görüş birliği içinde olduğu obama ya daha yakın mahmut_gürer / ankara dünyanin gözü bugün washington da olacak ankara da süreci yakından izliyor ancak daha önceki abd başkanlık seçimlerinden farklı olarak bu kez kaygı seviyesi en alt düzeyde bunun nedeni ise her iki adayın da dış politika projeksiyonunun ankara ya ters bir noktasının bulunmaması diplomatik kaynaklara göre ankara mevcut başkan barack_obama ile yaklaşık 4 yıldır oldukça yakın çalışıyor bu süre içerisinde özellikle terörle mücadele istihbarat ortaklığı ortadoğu gibi konularda çok yakın işbirliği sağlandı ankara obama nın seçilmesi durumunda ilişkilerin aynı şekilde devam etmesini öngörüyor bu nedenle abd halkının obama yı tercih etmesi istemi ankara da daha ağır basıyor ankara nın bu yaklaşımının temel nedenini ise obama ile yürütülen stratejik ve model ortaklık politikasının devamı oluşturuyor obama ile yakalanan bu süreç abd ile türkiye arasında şimdiye kadar yakalanan en verimli ortaklık olarak tanımlanıyor obama nin artilari abd_başkanı nın ilk ikili yurtdışı ziyaretini ankara ya yapmış olması israil i filistin konusunda çözüme zorlaması ve iran a olası bir askeri müdahaleye sıcak yaklaşmaması da türkiye nin obama ya sıcak bakmasındaki etkenler olarak sıralanıyor iki adaya ankara nın genel bakışı şöyle özetlenebilir iran ve predator ihtilafı ankara obama yönetimiyle 4 yıldır çok yakın biçimde mesai yapıyor özellikle ortadoğu konusunda ortak adımlar atılması kürecik te nato radarının yerleştirilmesinde hiçbir sorun yaşanmaması george_bush döneminde başlayan terörle mücadelede istihbarat paylaşımının sürmesi ankara yı mutlu ediyor obama nin danıştığım 5 liderden biri erdoğan açıklaması ve her ay cia başkanı genelkurmay_başkanı dışişleri_bakanı gibi üst düzey isimlerin ankara da temaslarda bulunması obama nın türkiye ye verdiği önemi de gösteriyor obama nın filistin israil çözümsüzlüğünde daha tarafsız bir tavır takınması mavi_marmara nın ardından israil e de türkiye ye de eşit mesafede bulunması ankara nın takdirini kazandı obama sözde ermeni soykırımı iddiaları ile ilgili olarak ilk seçim kampanyasında sözler vermiş olmasına karşın ankara yı kıracak herhangi bir adım atmadı ancak 2015 te senato dan sözde soykırımın tanınması doğrultusunda bir yasa geçmesi durumunda bunu veto edip etmeyeceği net değil bu belirsizlik obama nın eksi hanesine yazılıyor ankara nın obama yönetimiyle ilgili iki hayal kırıklığı bulunuyor ilki obama nın türkiye tarafından yoğun uğraşlarla oluşturulan ve iran ın nükleer çalışmalarını kontrol altına alan tahran anlaşmasını veto etmesi ikincisi ise türkiye nin terörle mücadelede kullanmak üzere ısrarla istediği silahlı predator türü insansız hava araçları için kongreden onay alamaması israil siyaseti can sıkabilir mitt romney in a takımı george_bush dönemindeki isimlerden oluşuyor bu da ankara ya romney in seçilmesi durumunda izleyeceği politikayla ilgili fikir veriyor romney in başkan olması durumunda ortadoğu terörle mücadelede ortaklık istihbarat işbirliği ve güvenlik işbirliği gibi konularda hiçbir sıkıntı yaşanması beklenmiyor romney seçilirse 2015 te sözde ermeni soykırımı ile ilgili herhangi bir yasanın onaylanmasına ankara pek olası bakmıyor ankara romney le sıkıntı yaşanması olası tek konuyu türkiye israil krizi olarak görüyor obama israil e daha mesafeli bir politika belirlemiş olmasına karşın romney in bazı konularda israil in çıkarlarını türkiye nin çıkarlarının üzerinde tutabileceği konuşuluyor romney bir konuşmasında başkan olduğum zaman ilk gezimi obama nın yaptığı gibi kahire veya ankara ya değil kudüs e yapacağım demişti\n",
            "Token IDs: tensor([     2,   3086,  15751,   1956,   3759,   2869,   8488,   4870,  27107,\n",
            "          3684,   2676,  43678,  10715,  40395,  16853,  43678,  13286,   5549,\n",
            "          3086,     24,   3955,  67227,   3945,  53874,  83940,  26564,  15500,\n",
            "         15751,   1956,   2122,   3001,   9964,     41,   5623,   1926,     19,\n",
            "          3086,  92600,  21309,   1012,  27107,   8926,   1972,   2645,   3086,\n",
            "          1972,  93534,   1010,   7204,  11116,   2591,   2122,  95266,   2869,\n",
            "         34449,   2045,  75030,   2937,   2693,   2095,   1964,   3098,  10423,\n",
            "         11154,   2064,   2401,  26679, 113146,   2713,   5553,   2319,   2110,\n",
            "          2537,  20713,   1972,  75582,   4855, 124676,   4407,   3086,   1956,\n",
            "          5646,   1947,  39558,  21395,  14934,  22717,  22586,   3086,   3844,\n",
            "         34449,  38669,     41,  15751,   2037, 101061,     24,   3955,  40180,\n",
            "          3001,  52565,   2335,   1964,  25994,  74925,  49138,  83872,   1939,\n",
            "         92126,  19844,  12211,  62409,   2893,   2692, 108723,   2166,   7318,\n",
            "          6110,   3001, 127599,  16133,   9598,   3214,   3086,  15751,   2437,\n",
            "          8488,   2836,   4750,  93520,   2174,   2573,  18011,   2524,  11418,\n",
            "          2121,  12707,   2407,   1964,   4099,   2869,   9063,  15751,   3716,\n",
            "          3307,   5753,  35496,   3086,   1972,   2122,  84100,  35976,   3086,\n",
            "          2437,   1964,  30647,  43173,   3361,  17372,   2319,  15751,   2037,\n",
            "          6131,   6997,   2074,   8263,   1946,   3242,  11295,  21980,   7900,\n",
            "         38166,   2407,  15751,   2037,  15164,   1964,  93534,   2869,   2037,\n",
            "         22918,   2605,  99037,   2185,  15164,   2064,   7657,  11295,   2095,\n",
            "         48672,  15751,   2276,  64670,   4664,   2869,     41,  34449,   1022,\n",
            "          2437,   2382,   9347,   6371,   2485,  39599,   3086,   1956, 126746,\n",
            "          1017,   2855,  38585,     51,   6808,   3081,  80784,   1011,  82030,\n",
            "          1946,  34187,     43,   5972,   1947,   4934, 117746,  14360,   3759,\n",
            "         30647,   6787,   1972,  22918,   2276,  15751,   1956,   3759,  69328,\n",
            "          2231,  27389,   2095,  50591,   2537,  18500,   3086,   2437,   2468,\n",
            "         20399,   2485,  28276, 123268,  14087,  34187,      3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4YUhZxyCwVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQJJAr1e_a4",
        "colab_type": "text"
      },
      "source": [
        "oluşturduğumuz tensor verisini modele vermek üzere *dataloader* değişkenine dönüştürüyoruz. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUsi4QGBxQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxa9wOcVCzq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_categories = len(df['encoded_categories'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zow9XGXVfNhS",
        "colab_type": "text"
      },
      "source": [
        "tokenizer'da olduğu gibi, önceden train edilmiş olan modeli fine tune etmek için hugging face'ten indiriyoruz. modelin özelliklerine aşağıdaki linkten ulaşabilirsiniz: \n",
        "https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/bert-base-turkish-128k-uncased/config.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNDxpE3C2bP",
        "colab_type": "code",
        "outputId": "c1523fc5-1b4c-408c-e7b4-1bafcf2f0bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
        "    num_labels = number_of_categories, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoEqn64XfjX3",
        "colab_type": "text"
      },
      "source": [
        "training'den önceki son adımda, toplam training adım sayısını ve kaç kere training yapılacağı sayısını belirliyoruz. bu sayıların yanında, öğrenmenin daha verimli olabilmesi ve *learning rate* optimizasyonu için bir scheduler yaratılıyor ve optimizer olarak *Adam Optimizer* kullanılıyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPL4qSPkC8hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqFHIKBhE9wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or7cXZA9DPs4",
        "colab_type": "code",
        "outputId": "c8627e8e-cc33-4426-ffc1-6e85368b13b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 1903\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Batch    10  of    123.    Elapsed: 0:00:08.\n",
            "Batch    20  of    123.    Elapsed: 0:00:15.\n",
            "Batch    30  of    123.    Elapsed: 0:00:23.\n",
            "Batch    40  of    123.    Elapsed: 0:00:31.\n",
            "Batch    50  of    123.    Elapsed: 0:00:39.\n",
            "Batch    60  of    123.    Elapsed: 0:00:46.\n",
            "Batch    70  of    123.    Elapsed: 0:00:54.\n",
            "Batch    80  of    123.    Elapsed: 0:01:02.\n",
            "Batch    90  of    123.    Elapsed: 0:01:10.\n",
            "Batch   100  of    123.    Elapsed: 0:01:17.\n",
            "Batch   110  of    123.    Elapsed: 0:01:25.\n",
            "Batch   120  of    123.    Elapsed: 0:01:33.\n",
            "Average training loss: 0.51\n",
            "Training epoch took: 0:01:35\n",
            "======== Epoch 2 / 4 ========\n",
            "Batch    10  of    123.    Elapsed: 0:00:08.\n",
            "Batch    20  of    123.    Elapsed: 0:00:15.\n",
            "Batch    30  of    123.    Elapsed: 0:00:23.\n",
            "Batch    40  of    123.    Elapsed: 0:00:31.\n",
            "Batch    50  of    123.    Elapsed: 0:00:39.\n",
            "Batch    60  of    123.    Elapsed: 0:00:46.\n",
            "Batch    70  of    123.    Elapsed: 0:00:54.\n",
            "Batch    80  of    123.    Elapsed: 0:01:02.\n",
            "Batch    90  of    123.    Elapsed: 0:01:09.\n",
            "Batch   100  of    123.    Elapsed: 0:01:17.\n",
            "Batch   110  of    123.    Elapsed: 0:01:25.\n",
            "Batch   120  of    123.    Elapsed: 0:01:33.\n",
            "Average training loss: 0.15\n",
            "Training epoch took: 0:01:35\n",
            "======== Epoch 3 / 4 ========\n",
            "Batch    10  of    123.    Elapsed: 0:00:08.\n",
            "Batch    20  of    123.    Elapsed: 0:00:15.\n",
            "Batch    30  of    123.    Elapsed: 0:00:23.\n",
            "Batch    40  of    123.    Elapsed: 0:00:31.\n",
            "Batch    50  of    123.    Elapsed: 0:00:39.\n",
            "Batch    60  of    123.    Elapsed: 0:00:46.\n",
            "Batch    70  of    123.    Elapsed: 0:00:54.\n",
            "Batch    80  of    123.    Elapsed: 0:01:02.\n",
            "Batch    90  of    123.    Elapsed: 0:01:09.\n",
            "Batch   100  of    123.    Elapsed: 0:01:17.\n",
            "Batch   110  of    123.    Elapsed: 0:01:25.\n",
            "Batch   120  of    123.    Elapsed: 0:01:33.\n",
            "Average training loss: 0.07\n",
            "Training epoch took: 0:01:35\n",
            "======== Epoch 4 / 4 ========\n",
            "Batch    10  of    123.    Elapsed: 0:00:08.\n",
            "Batch    20  of    123.    Elapsed: 0:00:15.\n",
            "Batch    30  of    123.    Elapsed: 0:00:23.\n",
            "Batch    40  of    123.    Elapsed: 0:00:31.\n",
            "Batch    50  of    123.    Elapsed: 0:00:39.\n",
            "Batch    60  of    123.    Elapsed: 0:00:46.\n",
            "Batch    70  of    123.    Elapsed: 0:00:54.\n",
            "Batch    80  of    123.    Elapsed: 0:01:02.\n",
            "Batch    90  of    123.    Elapsed: 0:01:09.\n",
            "Batch   100  of    123.    Elapsed: 0:01:17.\n",
            "Batch   110  of    123.    Elapsed: 0:01:25.\n",
            "Batch   120  of    123.    Elapsed: 0:01:33.\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:34\n",
            "Training completed in 0:06:18 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEX93h5OE-pG",
        "colab_type": "code",
        "outputId": "7177581d-9356-402d-f75a-edf08d1e5d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXiV9Z338fc3G4QkJCxhy8aSQEA2NSK41V2gIzp12mqVTmfa2naqta1V0Xmu6UyfGdep00U6U7s41t2xtXWqgCIoLmxBAUXCIiQkyBLAhLCGkO/zxzmcJ9AACeTkPufk87quXJ5z5z7nfHIEPrnv37l/P3N3REREAJKCDiAiIrFDpSAiIhEqBRERiVApiIhIhEpBREQiVAoiIhKhUpAuy8xmmdnfdvS+IvHMdJ2CxBMz29Pibg/gIHA4fP8b7v5U56c6dWZ2MfCku+cHnUUEICXoACLt4e6ZR26bWSXwNXefe+x+Zpbi7k2dmU0kEej0kSQEM7vYzGrM7C4z2wo8Zma9zOzPZlZrZp+Gb+e3eMwbZva18O2vmNnbZvbv4X03mtmUU9x3iJktMLMGM5trZjPN7MlT+JlGhl+3zsxWmdm0Ft+bamYfhV9js5n9ILy9b/jnrDOzXWb2lpnp77m0mf6wSCIZAPQGioCbCf35fix8vxDYDzxygsefC6wB+gIPAr8xMzuFfZ8GlgB9gH8Gprf3BzGzVOB/gVeBfsCtwFNmNiK8y28InS7LAkYD88LbbwdqgFygP3APoHPE0mYqBUkkzcAP3f2gu+93953u/nt33+fuDcC/AZ85weOr3P1X7n4YeBwYSOgf1jbva2aFwDnAP7l7o7u/Dbx0Cj/LRCATuD/8PPOAPwM3hL9/CBhlZj3d/VN3f6/F9oFAkbsfcve3XAOH0g4qBUkkte5+4MgdM+thZr80syoz2w0sAHLMLPk4j9965Ia77wvfzGznvoOAXS22AVS38+cg/DzV7t7cYlsVkBe+fR0wFagyszfNbFJ4+0PAeuBVM9tgZjNO4bWlC1MpSCI59jfi24ERwLnu3hO4KLz9eKeEOsIWoLeZ9WixreAUnucToOCY8YBCYDOAuy9192sInVr6I/B8eHuDu9/u7kOBacD3zeyyU3h96aJUCpLIsgiNI9SZWW/gh9F+QXevAsqBfzaztPBv8Fef7HFm1r3lF6ExiX3AnWaWGv7o6tXAs+HnvdHMst39ELCb0KkzzOyvzKw4PL5RT+jjus2tvqhIK1QKksh+AqQDO4BFwOxOet0bgUnATuBfgecIXU9xPHmEyqvlVwGhEphCKP8vgC+7e0X4MdOByvBpsW+GXxOgBJgL7AEWAr9w9/kd9pNJwtPFayJRZmbPARXuHvUjFZHTpSMFkQ5mZueY2TAzSzKzycA1hM77i8Q8XdEs0vEGAH8gdJ1CDfAtd38/2EgibaPTRyIiEqHTRyIiEhF3p4/69u3rgwcPDjqGiEhcWbZs2Q53zz3ZfnFXCoMHD6a8vDzoGCIiccXMqtqyn04fiYhIhEpBREQiVAoiIhKhUhARkQiVgoiIRKgUREQkQqUgIiIRCV0Kizfs5BdvrA86hohI3EjoUphXsZ2H5qxh9ZbdQUcREYkLCV0K/3BxMT27p3L/rIqT7ywiIoldCtk9Urn10mLeXFvL2+t2BB1HRCTmRbUUzGyyma0xs/VmNqOV73/FzGrNbHn462sdnWH6pCLye6Vz36zVNDdrmnARkROJWimYWTIwk9Aas6OAG8xsVCu7Pufu48Nfv+7oHN1SkrnjqhGs+mQ3L634pKOfXkQkoUTzSGECsN7dN7h7I/AsoWUJO93VYwcxJi+bh+as4cChw0FEEBGJC9EshTygusX9mvC2Y11nZivN7AUzK2jticzsZjMrN7Py2tradgdJSjLunlrK5rr9/G5hZbsfLyLSVQQ90Py/wGB3Hwu8Bjze2k7u/qi7l7l7WW7uSdeIaNV5w/pyyYhcHpm3nrp9jaeeWEQkgUWzFDYDLX/zzw9vi3D3ne5+MHz318DZUczDjCkj2XOwiZnzdUGbiEhrolkKS4ESMxtiZmnA9cBLLXcws4Et7k4DVkcxDyMGZPE3Z+fz+LtVVO/aF82XEhGJS1ErBXdvAm4B5hD6x/55d19lZj8ys2nh3b5jZqvMbAXwHeAr0cpzxPeuGE5SEvz41TXRfikRkbhj7vH12f2ysjI/3TWaH5pTwcz5H/PnWy9gdF52ByUTEYldZrbM3ctOtl/QA82B+MZnhtE7I417X1lNvJWiiEg0dclS6Nk9le9cWsy7H+/kzbXt/4iriEii6pKlAPClc4sY3KcH98+q4LCmvxARAbpwKaSlJHHn5FIqtjbw+/dqgo4jIhITumwpAEwZPYDxBTk8/Opa9jdq+gsRkS5dCmbGPVNHsnX3AX77zsag44iIBK5LlwLAhCG9uWJUf/7zjY/ZuefgyR8gIpLAunwpANw1uZT9hw7z83ma/kJEujaVAlDcL5MvnlPAk4uqqNyxN+g4IiKBUSmEfffyEtJSknhI01+ISBemUgjrl9Wdr184lJdXbuH9TZ8GHUdEJBAqhRa+ftFQ+mZ2475ZFZr+QkS6JJVCC5ndUvju5SUs2biLuau3Bx1HRKTTqRSOcf05BQzNzeD+WatpOtwcdBwRkU6lUjhGSnISMyaX8nHtXp4v1/QXItK1qBRaccWo/pwzuBf/MXctew82BR1HRKTTqBRaYWbcPXUktQ0H+fVbmv5CRLoOlcJxnFXYi6ljBvDLBR9T26DpL0Ska1ApnMAdV5XS2NTMT19fG3QUEZFOoVI4gSF9M7jx3EKeWVLNx7V7go4jIhJ1KoWTuPWyEtJTk3lwdkXQUUREok6lcBJ9M7vxzc8MZc6qbSyt3BV0HBGRqFIptMFXLxhK/57duPeV1Zr+QkQSmkqhDdLTkrn9ihG8v6mO2R9uDTqOiEjUqBTa6Lqz8xneP5MHZldwSNNfiEiCUim0UXKScfeUkVTu3MczSzYFHUdEJCpUCu1w8YhcJg3tw0/nrqPhwKGg44iIdDiVQjuEpr8oZefeRh5dsCHoOCIiHU6l0E5j83OYNm4Qv3prA9t2Hwg6johIh1IpnII7rhrB4WbnP17T9BciklhUCqegoHcPvjxpMM+XV7N2W0PQcUREOkxUS8HMJpvZGjNbb2YzTrDfdWbmZlYWzTwd6ZZLisnolsL9szT9hYgkjqiVgpklAzOBKcAo4AYzG9XKflnAbcDiaGWJhl4ZaXz7kmLmVWzn3Y93BB1HRKRDRPNIYQKw3t03uHsj8CxwTSv7/V/gASDuRm2/ct5gBmV35/5ZFTQ3a/oLEYl/0SyFPKC6xf2a8LYIMzsLKHD3l0/0RGZ2s5mVm1l5bW1txyc9Rd1Tk/nBVSNYWVPPnz/YEnQcEZHTFthAs5klAQ8Dt59sX3d/1N3L3L0sNzc3+uHa4drxeYwc2JOH5lRwsOlw0HFERE5LNEthM1DQ4n5+eNsRWcBo4A0zqwQmAi/F02AzQFKScc/UUqp37efJRZr+QkTiWzRLYSlQYmZDzCwNuB546cg33b3e3fu6+2B3HwwsAqa5e3kUM0XFhSW5XFjSl5/PW0f9fk1/ISLxK2ql4O5NwC3AHGA18Ly7rzKzH5nZtGi9blBmTCmlfv8h/vONj4OOIiJyylKi+eTu/grwyjHb/uk4+14czSzRdsagbP76zDx++85Gpk8qIi8nPehIIiLtpiuaO9DtV44A4Mevrgk4iYjIqVEpdKC8nHT+7vzBvPj+ZlZ9Uh90HBGRdlMpdLB/uLiY7PRUTX8hInFJpdDBstNTueWSYt5at4MFa2PnQjsRkbZQKUTB9ElFFPRO5z5NfyEicUalEAXdUpK546pSVm/ZzR+Xbz75A0REYoRKIUr+asxAxuZn8+9z1nDgkKa/EJH4oFKIkqQkY8aUUj6pP8Dj71YGHUdEpE1UClF03rC+XFraj0fmr+fTvY1BxxEROSmVQpTdNbmUvQebeGT++qCjiIiclEohykYMyOLzZxfwu4WVVO/aF3QcEZETUil0gu9dMZzkJOOhOZr+QkRim0qhEwzI7s7XLhjKSys+YWVNXdBxRESOS6XQSb7xmaH0zkjj3ldW464L2kQkNqkUOklW91Ruu6yERRt28cYaTX8hIrFJpdCJvnRuIUP6ZnDfrNUc1vQXIhKDVAqdKDU5iTuvGsHabXv4/bKaoOOIiPwFlUInmzx6AGcW5vDj19awv1HTX4hIbFEpdDIz456pI9m2+yC/eXtD0HFERI6iUgjAOYN7c+Wo/vzXmxvYsedg0HFERCJUCgG5c3Ip+w8d5uevrws6iohIhEohIMX9Mrn+nAKeWryJjTv2Bh1HRARQKQTqtstLSEtJ4qE5Ws9ZRGKDSiFA/bK6c/NFQ3nlg628t+nToOOIiKgUgvb1C4eSm9WN+zT9hYjEAJVCwDK6pfC9y4eztPJTXvtoW9BxRKSLUynEgC+U5TMsN4P7Z1fQdLg56Dgi0oWpFGJASnISM6aMZEPtXp5dWh10HBHpwlQKMeLykf2YMLg3P5m7lj0Hm4KOIyJdlEohRpgZd08tZceeRn61QNNfiEgwVAox5MzCXnx2zEB+9dYGtu8+EHQcEemCVAox5o6rRtDY1MxPNP2FiAQgqqVgZpPNbI2ZrTezGa18/5tm9oGZLTezt81sVDTzxIPBfTO4aWIRzy2tZv32hqDjiEgXE7VSMLNkYCYwBRgF3NDKP/pPu/sYdx8PPAg8HK088eTWS4tJT03mgdlrgo4iIl1MNI8UJgDr3X2DuzcCzwLXtNzB3Xe3uJsB6JJeoE9mN7518TBe+2gbSzbuCjqOiHQh0SyFPKDlh+5rwtuOYmbfNrOPCR0pfKe1JzKzm82s3MzKa2u7xqL3f3/+EAb07M69mv5CRDpR4APN7j7T3YcBdwH/5zj7POruZe5elpub27kBA5Kelsz3rxzO8uo6Zn24Neg4ItJFRLMUNgMFLe7nh7cdz7PAtVHME3euOyufEf2zeGB2BY1Nmv5CRKIvmqWwFCgxsyFmlgZcD7zUcgczK2lx97OAPofZQnKSMWNqKVU79/H04qqg44hIF9CmUjCzDDNLCt8ebmbTzCz1RI9x9ybgFmAOsBp43t1XmdmPzGxaeLdbzGyVmS0Hvg/87Sn/JAnq4uG5nDesDz+bt57dBw4FHUdEEpy1ZRDTzJYBFwK9gHcIHQU0uvuN0Y33l8rKyry8vLyzXzZQH9TUc/Ujb/PtS4Zxx1WlQccRkThkZsvcvexk+7X19JG5+z7gc8Av3P3zwBmnE1Dabkx+NteMH8Sv39rIlvr9QccRkQTW5lIws0nAjcDL4W3J0YkkrfnBlSNwh/94bW3QUUQkgbW1FL4L3A28GB4XGArMj14sOVZB7x58eVIRLyyroWLr7pM/QETkFLSpFNz9TXef5u4PhAecd7h7qxeaSfTccmkxmd1SeGBWRdBRRCRBtfXTR0+bWU8zywA+BD4yszuiG02OldMjjW9fUsz8NbW8u35H0HFEJAG19fTRqPA8RdcCs4AhwPSopZLj+tvzBpOXk869s1bT3KzpL0SkY7W1FFLD1yVcC7zk7ofQ5HWB6J6azA+uGs6Hm3fzvys/CTqOiCSYtpbCL4FKQjOZLjCzIkCjnQG5Zlweowb25MHZazjYdDjoOCKSQNo60Pwzd89z96keUgVcEuVschxJScY9U0eyuW4/TyzU9Bci0nHaOtCcbWYPH5m+2sx+TOioQQJyQUlfLhqey8/nrad+n6a/EJGO0dbTR78FGoAvhL92A49FK5S0zYzJpew+cIhfvLE+6CgikiDaWgrD3P2H4VXUNrj7vwBDoxlMTm7UoJ587sx8Hnu3kppP9wUdR0QSQFtLYb+ZXXDkjpmdD2gSnhhw+5XDAXj4VU1/ISKnr62l8E1gpplVmlkl8AjwjailkjYblJPO358/hBeXb+bDzfVBxxGRONfWTx+tcPdxwFhgrLufCVwa1WTSZt+6eBjZ6ancP6tC6zmLyGlp18pr7r47fGUzhBbFkRiQnZ7KrZeW8Pb6HSxYp+kvROTUnc5ynNZhKeS0TZ9YRGHvHtz3ymoOa/oLETlFp1MK+pcnhqSlJHHHVSOo2NrAi+9vDjqOiMSpE5aCmTWY2e5WvhqAQZ2UUdros2MGMi4/mx+/uoYDhzT9hYi03wlLwd2z3L1nK19Z7p7SWSGlbZKSjBlTRrKl/gCPvVMZdBwRiUOnc/pIYtCkYX24rLQfv5i/nl17G4OOIyJxRqWQgO6aUsrexiYemafpL0SkfVQKCWh4/yy+UFbAE4sq2bRT01+ISNupFBLU964YTnKS8eAcrecsIm2nUkhQ/Xt25+sXDuXPK7ewvLou6DgiEidUCgns5ouG0icjjfteWa3pL0SkTVQKCSyreyrfvbyExRt3Ma9ie9BxRCQOqBQS3PUTChnSN4P7Z1XQdLg56DgiEuNUCgkuNTmJuyaPYN32PbywrCboOCIS41QKXcBVZwzgrMIcHn5tLfsam4KOIyIxTKXQBZgZ90wdyfaGg/zmrY1BxxGRGKZS6CLKBvfmqjP6819vfsyOPQeDjiMiMSqqpWBmk81sjZmtN7MZrXz/+2b2kZmtNLPXzawomnm6ujsnl3KgqZmfvb4u6CgiEqOiVgpmlgzMBKYAo4AbzGzUMbu9D5S5+1jgBeDBaOURGJabyQ0TCnh68SY21O4JOo6IxKBoHilMANa7+wZ3bwSeBa5puYO7z3f3I5PzLALyo5hHgNsuG05aShIPzl4TdBQRiUHRLIU8oLrF/ZrwtuP5KjCrtW+Y2c1mVm5m5bW1tR0YsevJzerGNy4axuxVW1lWtSvoOCISY2JioNnMbgLKgIda+767P+ruZe5elpub27nhEtDXLhxCblY37n2lQtNfiMhRolkKm4GCFvfzw9uOYmaXA/8ITHN3fSymE2R0S+H7VwxnWdWnzFm1Leg4IhJDolkKS4ESMxtiZmnA9cBLLXcwszOBXxIqBE3O04k+f3Y+xf0yeXB2BYc0/YWIhEWtFNy9CbgFmAOsBp5391Vm9iMzmxbe7SEgE/gfM1tuZi8d5+mkg6UkJzFjcikbduzl2aXVJ3+AiHQJKdF8cnd/BXjlmG3/1OL25dF8fTmxy0b2Y8KQ3vx07lr++sw8MrtF9Y+DiMSBmBholmAcmf5ix55GHl2wIeg4IhIDVApd3PiCHD47diC/WrCBbbsPBB1HRAKmUhDuvGoETc3N/GTu2qCjiEjAVApCUZ8Mbjy3iOeWVrNuW0PQcUQkQCoFAeDWS4vJSEvhgdkVQUcRkQCpFASAPpnd+ObFw5i7ejuLNuwMOo6IBESlIBFfvWAIA7O7c98rqzX9hUgXpVKQiO6pyXz/iuGsqKnn5Q+2BB1HRAKgUpCjfO6sfEoHZPHg7DU0Nmn6C5GuRqUgR0lOMmZMKWXTrn08tbgq6Dgi0slUCvIXPjM8l/OL+/Cz19dRv/9Q0HFEpBOpFOQvmBl3TxnJp/sO8V9vfhx0HBHpRCoFadXovGyuHT+I3769kU/q9gcdR0Q6iUpBjuv2K0fgDn/zn+8yc/56ahu0BpJIolMpyHEV9O7BY393DkNyM3hozhrOu/91bnv2fcord+k6BpEEpQn05YTOL+7L+cV9Wb99D08uquL3y2r40/JPKB2QxfRJRVw7Po8MrcMgkjAs3n7jKysr8/Ly8qBjdFn7Gpv40/JP+N3CKlZv2U1mtxSuOyuPmyYWUdI/K+h4InIcZrbM3ctOup9KQU6Fu/PepjqeXFTFyyu30Hi4mYlDe/PlSYO5YlR/UpN1ZlIklqgUpNPs3HOQ58qreWrRJjbX7adfVjdumFDIDRMKGZDdPeh4IoJKQQJwuNl5Y812nlhUxZtra0ky48pR/Zk+sYhJw/pgZkFHFOmy2loKGiGUDpOcZFw2sj+XjexP1c69PL14E8+VVzPrw60My81g+sQiPnd2Pj27pwYdVUSOQ0cKElUHDh3m5ZVbeGJRFcur60hPTebaM/OYPrGIUYN6Bh1PpMvQ6SOJOR/U1PPEokr+tPwTDjY1c3ZRL6ZPLGLKmAF0S0kOOp5IQlMpSMyq29fIC8tqeHJRFZU799EnI40vnFPAjecWkt+rR9DxRBKSSkFiXnOz887HO/jdwipeX70NBy4r7cdNE4u4qCSXpCQNTIt0FA00S8xLSjIuLMnlwpJcNtft55nFm3h26Sbmrt5OYe8e3DSxkM+fXUCvjLSgo4p0GTpSkJjS2NTM7FVbeXJhFUsqd5GWksTVYwcxfVIR4wtygo4nErd0+kjiXsXW3Ty5qIoX39vM3sbDjM3P5qaJRVw9dhDpaRqYFmkPlYIkjIYDh/jj+5v53cIq1m3fQ3Z6Kp8/O58bJxYxpG9G0PFE4oJKQRKOu7N44y6eWFTFnA+30tTsXFjSl+kTi7hsZH+SNTAtclwaaJaEY2ZMHNqHiUP7sH33AZ5dWs3Tizdx8xPLyMtJ50vnFvKFsgJys7oFHVUkbkX1SMHMJgM/BZKBX7v7/cd8/yLgJ8BY4Hp3f+Fkz6kjBWmp6XAzc1dv54lFlbyzfiepycaU0QOZPqmIsqJemm9JJCzwIwUzSwZmAlcANcBSM3vJ3T9qsdsm4CvAD6KVQxJbSnISk0cPYPLoAazfvoenFlfxwrIaXloRWgjopolFXHtmHplaCEikTaI56f0EYL27b3D3RuBZ4JqWO7h7pbuvBJqjmEO6iOJ+mfzw6jNYfM9l3P+5MSSZ8X/++CET732dH/7pQ9Ztawg6okjMi+avT3lAdYv7NcC5p/JEZnYzcDNAYWHh6SeThNYjLYXrJxTyxXMKeL+6jicXVvHMkmoeX1jFxKG9mT5xMFeeoYWARFoTF8fU7v4o8CiExhQCjiNxwsw4q7AXZxX24h8/O5Lny2t4anEV3376PfpldeP6CYV8SQsBiRwlmqWwGShocT8/vE2k0/XJ7Ma3Lh7GzRcN5c2123liYRU/n7eOmfPXayEgkRaiWQpLgRIzG0KoDK4HvhTF1xM5qeQk49LS/lxa2p9NO/fx1JIqnl8aWgho6JGFgM7KJztdCwFJ1xTtj6ROJfSR02Tgt+7+b2b2I6Dc3V8ys3OAF4FewAFgq7ufcaLn1EdSpaO1vhDQIG6aWMQZg7KDjifSIXRFs8gp+KCmnicXVfGnFZs5cKiZswpzmD6piCmjB9I9VfMtSfxSKYichvp9h3jhvdBCQBt37KV3RhpfPKeAL00opKC3FgKS+KNSEOkAzc3Oux/v5HcLK5kbXgjo0hH9uGlSEZ/RQkASRwK/olkkESQlGReU9OWCkr58UrefZ5Zs4pkl1bz+2FIKe/fgxvB8S1oISBKFjhRE2qmxqZk5q7byxKIqlmw8eiGgcfnZ+lirxCSdPhLpBGu2NvDkoir+8F4NexsPMyYvm+kTi7h6nBYCktiiUhDpREcWAnpiURVrt+2hZ/cUPl9WwI3nFjI0NzPoeCIqBZEguDtLwgsBzQ4vBHR+cR/OL+7L+PwcRudn07O7LoyTzqeBZpEAmBnnDu3DuUP7sL3hAM8tqeYP72/mwdlrIvsMy81gXH4OY/OzGVeQw8iBPXUNhMQMHSmIdIK6fY2srKlnRXUdK2rqWVFTR23DQQBSk43SAT1DJZGfw7iCHIr7ZWp5UelQOn0kEsPcna27D7CiOlQQK2vqWFlTT8OBJgB6pCUzelA24wqyGZufw7j8HAp6p+uTTXLKdPpIJIaZGQOz0xmYnc7k0QOA0IVyG3fuZWVNXaQsHl9YRWPTRgB69UgNFURBDuPyQ2Wh9ailo+lIQSSGHTrczJqtDaGjiXBRrN3WQHP4r21eTjpjwwUxriCbMXnZZGkgW1qhIwWRBJCanMTovGxG52VzY3jdwn2NTXy4eXfoiCI8TjHrw60AmMGw3MyjxidGDsyiW4oGsqVtVAoicaZHWgoThvRmwpDekW2f7m0Mj03Us7KmjgVrd/CH90JrWh0ZyG45PqGBbDkenT4SSUDuzpb6A6ysqWN5dagoPqipp+Fgi4HsvGzGF+REjirye2kgO5Hp9JFIF2ZmDMpJZ1BOOpNHDwRCA9kbdhwZyA6devrvdytpbGoGoHdGWmR8Ynz4qKJvpgayuxqVgkgXkZRkFPfLpLhfJp87Kx8ITe4XGcgOf+ppwdp1Rw1ktzztNCY/m8xu+mcjken/rkgXlpaSxJj8bMbkZwNFAOw92MSHm+tDF9vV1LGipo5XPjh6IHtc+NNOY/M1kJ1oVAoicpSMbimRqTqO2LW3MXIksbKmjjfXbuf379UAoYHskQN7HjV1x7BcDWTHKw00i0i7uTuf1B9gZXUdy8PXUHywuZ494YHsjPBAduhCu1BZaCA7WBpoFpGoMTPyctLJy0lnypiWA9l7IkcTy2vq+e93Kmk8HBrI7nPUQHaoKPpoIDvmqBREpEOEBrKzKO6XxXVn//+B7Iqtu1lRU8/K6tD4xBtra/EWA9lHCmKsBrJjgt59EYmatJQkxubnMDY/ByYePZC9osUV2S9/sAUIDWQX52YeNb9TqQayO5VKQUQ6VWsD2Tv3HGTl5lBBrKypZ37Fdl5YFhrITktOYtSgnvzPNyeRmpwUVOwuQ6UgIoHrk9mNS0b045IR/YDQQPbmuv2RNShqGw6qEDqJSkFEYo6Zkd+rB/m9ejA1PJAtnUPVKyIiESoFERGJUCmIiEiESkFERCJUCiIiEqFSEBGRCJWCiIhEqBRERCQi7qbONrNaoCroHF1MX2BH0CHinN7D06P37/SNcPesk+0Ud1c0u3tu0Bm6GjMrb8s87HJ8eg9Pj96/02dmbVqIRqePREQkQqUgIiIRKgVpi0eDDpAA9B6eHr1/p69N72HcDTSLiEj06EhBREQiVAoiIhKhUpDjMrPfmtl2M/sw6CzxyMwKzGy+mX1kZqvM7LagM8UbM+tuZkvMbEX4PfyXoDPFIzNLNrP3zezPJ9tXpSAn8t/A5KBDxLEm4HZ3HwVMBL5tZqMCzhRvDgKXuvs4YDww2cwmBpwpHt0GrG7LjioFOS53XwDsCjpHvHL3Le7+Xvh2A6G/lHnBpqH381UAAAKgSURBVIovHrInfDc1/KVPx7SDmeUDnwV+3Zb9VQoincDMBgNnAouDTRJ/wqc+lgPbgdfcXe9h+/wEuBNobsvOKgWRKDOzTOD3wHfdfXfQeeKNux929/FAPjDBzEYHnSlemNlfAdvdfVlbH6NSEIkiM0slVAhPufsfgs4Tz9y9DpiPxrna43xgmplVAs8Cl5rZkyd6gEpBJErMzIDfAKvd/eGg88QjM8s1s5zw7XTgCqAi2FTxw93vdvd8dx8MXA/Mc/ebTvQYlYIcl5k9AywERphZjZl9NehMceZ8YDqh386Wh7+mBh0qzgwE5pvZSmApoTGFk36sUk6dprkQEZEIHSmIiEiESkFERCJUCiIiEqFSEBGRCJWCiIhEqBREjmFmh1t8hHS5mc3owOcerFlnJZalBB1AJAbtD0+rINLl6EhBpI3MrNLMHjSzD8Jz/BeHtw82s3lmttLMXjezwvD2/mb2YngtgBVmdl74qZLN7Ffh9QFeDV+pKxITVAoifyn9mNNHX2zxvXp3HwM8Qmj2SYCfA4+7+1jgKeBn4e0/A94MrwVwFrAqvL0EmOnuZwB1wHVR/nlE2kxXNIscw8z2uHtmK9srCS34siE80d1Wd+9jZjuAge5+KLx9i7v3NbNaIN/dD7Z4jsGEpmooCd+/C0h193+N/k8mcnI6UhBpHz/O7fY42OL2YTS2JzFEpSDSPl9s8d+F4dvvEpqBEuBG4K3w7deBb0FkoZjszgopcqr0G4rIX0oPr/R1xGx3P/Kx1F7hGTsPAjeEt90KPGZmdwC1wN+Ft98GPBqeXfYwoYLYEvX0IqdBYwoibRQeUyhz9x1BZxGJFp0+EhGRCB0piIhIhI4UREQkQqUgIiIRKgUREYlQKYiISIRKQUREIv4fAMXwFtp9Sq8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa3aIdMyJwm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_texts = test.text.values\n",
        "test_labels = test.encoded_categories.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in test_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_len,          \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',   \n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxGSl8Efe8JM",
        "colab_type": "text"
      },
      "source": [
        "test verisini kullanarak modele sonuçları tahmin ettiriyoruz. batch değerimiz 32 olduğu için, model training'de olduğu gibi prediction kısmında da 32'şer 32'şer input'ları modele veriyor. o yüzden flatten fonksiyonu ile bütün sonuçları tek bir listede topluyoruz ve prediction_set değişkeninde saklıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNfzOIZKH82",
        "colab_type": "code",
        "outputId": "e9232658-1546-4b01-8eec-7030eee5e4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Prediction started on test data')\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Prediction completed')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction started on test data\n",
            "Prediction completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNJdxER7KeBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  prediction_set.append(pred_labels_i)\n",
        "\n",
        "prediction_scores = [item for sublist in prediction_set for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZXQhPf8fCdb",
        "colab_type": "text"
      },
      "source": [
        "bu bir sınıflandırma problemi olduğu için performans metriklerinden F-score'u kullanmak istedim. bu kısımda Precision, Recall ve F-score değerlerini çıkartıyoruz, modelin performansını gözlemliyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk4NmFh0KjLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
        "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
        "recall = recall_score(test_labels, prediction_scores, average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQaJueaUKlQf",
        "colab_type": "code",
        "outputId": "c03b7eb2-170b-4de2-e7a5-60d6cb5e3f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"F-Score: \", f_score)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-Score:  0.91992270045502\n",
            "Recall:  0.9210612904649649\n",
            "Precision:  0.9196331265833295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTaAxtnyKnzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyJ5RCD-Kqur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = report.rename(columns={'0':'dunya',\n",
        "                          '1':'ekonomi',\n",
        "                          '2':'kultur',\n",
        "                          '3':'saglik',\n",
        "                          '4':'siyaset',\n",
        "                          '5':'spor',\n",
        "                          '6':'teknoloji'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjp7m2NRMoRp",
        "colab_type": "code",
        "outputId": "93d4cf63-cf1e-41eb-a295-4fe482f16b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dunya</th>\n",
              "      <th>ekonomi</th>\n",
              "      <th>kultur</th>\n",
              "      <th>saglik</th>\n",
              "      <th>siyaset</th>\n",
              "      <th>spor</th>\n",
              "      <th>teknoloji</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.963855</td>\n",
              "      <td>0.930435</td>\n",
              "      <td>0.910448</td>\n",
              "      <td>0.959016</td>\n",
              "      <td>0.864662</td>\n",
              "      <td>0.916468</td>\n",
              "      <td>0.919633</td>\n",
              "      <td>0.916409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.893130</td>\n",
              "      <td>0.820896</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.963964</td>\n",
              "      <td>0.897059</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.916468</td>\n",
              "      <td>0.921061</td>\n",
              "      <td>0.916468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.914063</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.958084</td>\n",
              "      <td>0.946903</td>\n",
              "      <td>0.903704</td>\n",
              "      <td>0.979079</td>\n",
              "      <td>0.891473</td>\n",
              "      <td>0.916468</td>\n",
              "      <td>0.919923</td>\n",
              "      <td>0.915993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>131.000000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.916468</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                dunya     ekonomi  ...   macro avg  weighted avg\n",
              "precision    0.936000    0.873016  ...    0.919633      0.916409\n",
              "recall       0.893130    0.820896  ...    0.921061      0.916468\n",
              "f1-score     0.914063    0.846154  ...    0.919923      0.915993\n",
              "support    131.000000  134.000000  ...  838.000000    838.000000\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}